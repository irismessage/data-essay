{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "J_8Hl6RhR5Th",
   "metadata": {
    "id": "J_8Hl6RhR5Th"
   },
   "source": [
    "## Department of Computer Science, University of York\n",
    "### DATA: Introduction to Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833fc93b",
   "metadata": {
    "id": "833fc93b"
   },
   "source": [
    "## Task 1: Domain Analysis  (5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RbtRJd18asfN",
   "metadata": {
    "id": "RbtRJd18asfN"
   },
   "source": [
    "Given the business domain and the data overview presented (in the assessment paper), provide a brief description of\n",
    "\n",
    "* the business problem and its significance to the relevant sector;\n",
    "* the link between the business problem and the field of data science;\n",
    "* the main areas of investigation; and\n",
    "* potential ideas and solutions.\n",
    "\n",
    "\n",
    "**Word Limit:** 300 words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LQ_p4Qitu334",
   "metadata": {
    "id": "LQ_p4Qitu334"
   },
   "source": [
    "**Write your answer here (text cell(s) to be used, as appropriate)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "G8kyLn-xXG9O",
   "metadata": {
    "id": "G8kyLn-xXG9O"
   },
   "outputs": [],
   "source": [
    "### Write your answer here (code cell(s) to be used, as appropriate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326757ae",
   "metadata": {
    "id": "326757ae"
   },
   "source": [
    "\n",
    "----\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f0a14c",
   "metadata": {
    "id": "f2f0a14c"
   },
   "source": [
    "## Task 2: Database Design (25 marks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dC2nOMbbU5AG",
   "metadata": {
    "id": "dC2nOMbbU5AG"
   },
   "source": [
    "Having understood the business domain, present a conceptual design in the form of an entity-relationship (ER) model that would be helpful in creating a database for the bank.\n",
    "\n",
    "The bank data currently exists in the form of a csv file called *BankRecords.csv*, provided on VLE (path given in page 5, assessment paper). This file has all the existing records. The table available in the csv file is unnormalised. The information about its different columns is given in Tables 1 and 2 (in the assessment paper).\n",
    "\n",
    "Following the standard principles of database normalisation, normalise the given table (*BankRecords.csv*) to a database schema that has minimum redundancies. Then, using the designed schema, create an SQLite database.\n",
    "\n",
    "Your answer should include the SQL statements needed to accomplish this step. Your submission should also include the created SQLite database file.\n",
    "\n",
    "Your answer should clearly cover the following:\n",
    "* Any assumptions you are making about the given scenario;\n",
    "* The designated keys, existing relationships, and identified functional dependencies;\n",
    "* The steps followed and justifications for the decisions made.\n",
    "\n",
    "**World Limit**: 500 words. This limit applies only to the explanations. There is no limit on any associated code/SQL statements or figures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43203df7",
   "metadata": {
    "id": "43203df7"
   },
   "source": [
    "**Write your answer here (text cell(s) to be used, as appropriate)**\n",
    "\n",
    "For the ERM diagram, see `DATA Essay.jpg`.\n",
    "\n",
    "![ERM Diagram](DATA Essay.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5988039d-a777-44aa-93c3-e05b282f97b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a33ca09c",
   "metadata": {
    "id": "a33ca09c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting database\n",
      "Database didn't exist\n",
      "Creating database\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "### Write your answer here (code cell(s) to be used, as appropriate)\n",
    "\n",
    "# todo not nulls\n",
    "# todo constraints\n",
    "# todo the following classifier fields could be made integers:\n",
    "#     statementFrequency\n",
    "#     loanStatus\n",
    "#     transType\n",
    "#     dispType\n",
    "#     cardType\n",
    "\n",
    "sql_create = \"\"\"\n",
    "CREATE TABLE Account (\n",
    "    accountID INTEGER PRIMARY KEY,\n",
    "    statementFrequency TEXT,  -- frequency\n",
    "    creationDate TEXT\n",
    ");\n",
    "CREATE TABLE Loan (\n",
    "    loanID INTEGER PRIMARY KEY,\n",
    "    dispID INTEGER,\n",
    "    loanDate TEXT\n",
    "    loanAmount REAL,\n",
    "    loanDuration INTEGER,\n",
    "    loanPayments INTEGER,\n",
    "    loanStatus TEXT,\n",
    "    FOREIGN KEY (dispID) REFERENCES Disposition(dispID)\n",
    ");\n",
    "CREATE TABLE StandingOrder (\n",
    "    orderID INTEGER PRIMARY KEY,\n",
    "    dispID INTEGER\n",
    "    bankTo STRING,\n",
    "    accountTo INTEGER,\n",
    "    orderAmount REAL,\n",
    "    paymentType STRING,\n",
    "    FOREIGN KEY (dispID) REFERENCES Disposition(dispID)\n",
    ");\n",
    "CREATE TABLE BankTransaction (  -- Transaction is a reserved word\n",
    "    transID INTEGER PRIMARY KEY,\n",
    "    dispID INTEGER,\n",
    "    transDate TEXT,\n",
    "    transType TEXT,\n",
    "    operation TEXT,\n",
    "    transAmount REAL,\n",
    "    balance REAL,\n",
    "    transDetail TEXT,\n",
    "    partnerBank TEXT,\n",
    "    partnerAccount INTEGER,\n",
    "    FOREIGN KEY (dispID) REFERENCES Disposition(dispID)\n",
    ");\n",
    "CREATE TABLE Client (\n",
    "    clientID INTEGER PRIMARY KEY,\n",
    "    cityID INTEGER,  -- a1\n",
    "    birthDate TEXT,  -- birth_number\n",
    "    gender INTEGER,  -- birth_number\n",
    "    FOREIGN KEY (cityID) REFERENCES City(cityID)\n",
    ");\n",
    "CREATE TABLE Disposition (\n",
    "    dispID INTEGER PRIMARY KEY,\n",
    "    accountID INTEGER,\n",
    "    clientID INTEGER\n",
    "    dispType TEXT,\n",
    "    FOREIGN KEY (accountID) REFERENCES Account(accountID),\n",
    "    FOREIGN KEY (clientID) REFERENCES Client(clientID)\n",
    ");\n",
    "CREATE TABLE CreditCard (\n",
    "    cardID INTEGER PRIMARY KEY,\n",
    "    dispID INTEGER,\n",
    "    cardType TEXT,\n",
    "    cardIssued TEXT,\n",
    "    FOREIGN KEY (dispID) REFERENCES Disposition(dispID)\n",
    ");\n",
    "CREATE TABLE City (\n",
    "    cityID INTEGER PRIMARY KEY,  -- a1\n",
    "    cityName TEXT,\n",
    "    region TEXT,\n",
    "    inhabitants INTEGER,\n",
    "    muns0 INTEGER,\n",
    "    muns500 INTEGER,\n",
    "    muns2000 INTEGER,\n",
    "    muns10000 INTEGER,\n",
    "    noAreas INTEGER,\n",
    "    ratioUrban REAL,\n",
    "    avgSalary REAL,\n",
    "    unemployment1995 REAL,\n",
    "    unemployment1996 REAL,\n",
    "    entrepeneurs INTEGER,\n",
    "    crimes1995 INTEGER,\n",
    "    crimes1996 INTEGER  -- a16\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "sqlf = Path(\"BankRecords.db\")\n",
    "\n",
    "\n",
    "def create_db():\n",
    "    print(\"Deleting database\")\n",
    "    try:\n",
    "        sqlf.unlink()\n",
    "    except FileNotFoundError:\n",
    "        print(\"Database didn't exist\")\n",
    "    else:\n",
    "        print(\"Deleted database\")\n",
    "    \n",
    "    print(\"Creating database\")\n",
    "    con = sqlite3.connect(sqlf)\n",
    "    with con:\n",
    "        con.executescript(sql_create)\n",
    "    con.close()\n",
    "    print(\"Done\")\n",
    "\n",
    "create_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b603743e-4bce-4109-893c-32f15f5bc65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0690ff0d-59b5-4578-8fb1-0f0f6b1d9b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading csv\n",
      "Done in 14.1s\n"
     ]
    }
   ],
   "source": [
    "# load dataframe\n",
    "DATE_FORMAT_CSV = \"%y%m%d\"\n",
    "\n",
    "csvf = Path(\"BankRecords.csv\")\n",
    "\n",
    "print(\"Loading csv\")\n",
    "start_time = time.time()\n",
    "\n",
    "df = pd.read_csv(\n",
    "    csvf,\n",
    "    parse_dates=[\n",
    "        \"creation_date\",\n",
    "        \"loan_date\",\n",
    "        \"trans_date\",\n",
    "        \"card_issued\"\n",
    "    ],\n",
    "    date_format=DATE_FORMAT_CSV,\n",
    "    low_memory=False,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "print(f\"Done in {duration:.3}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f888f528-bf8a-4be8-bf0b-c4802946302e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>frequency</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>loan_id</th>\n",
       "      <th>loan_date</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>loan_duration</th>\n",
       "      <th>loan_payments</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>order_id</th>\n",
       "      <th>...</th>\n",
       "      <th>a7</th>\n",
       "      <th>a8</th>\n",
       "      <th>a9</th>\n",
       "      <th>a10</th>\n",
       "      <th>a11</th>\n",
       "      <th>a12</th>\n",
       "      <th>a13</th>\n",
       "      <th>a14</th>\n",
       "      <th>a15</th>\n",
       "      <th>a16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>1995-03-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29401.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>65.3</td>\n",
       "      <td>8968</td>\n",
       "      <td>2.83</td>\n",
       "      <td>3.35</td>\n",
       "      <td>131</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>1910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>1995-03-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29401.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>65.3</td>\n",
       "      <td>8968</td>\n",
       "      <td>2.83</td>\n",
       "      <td>3.35</td>\n",
       "      <td>131</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>1910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>1995-03-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29401.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>65.3</td>\n",
       "      <td>8968</td>\n",
       "      <td>2.83</td>\n",
       "      <td>3.35</td>\n",
       "      <td>131</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>1910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>1995-03-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29401.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>65.3</td>\n",
       "      <td>8968</td>\n",
       "      <td>2.83</td>\n",
       "      <td>3.35</td>\n",
       "      <td>131</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>1910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>1995-03-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29401.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>65.3</td>\n",
       "      <td>8968</td>\n",
       "      <td>2.83</td>\n",
       "      <td>3.35</td>\n",
       "      <td>131</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>1910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_id frequency creation_date  loan_id loan_date  loan_amount  \\\n",
       "0           1   Monthly    1995-03-24      NaN       NaT          NaN   \n",
       "1           1   Monthly    1995-03-24      NaN       NaT          NaN   \n",
       "2           1   Monthly    1995-03-24      NaN       NaT          NaN   \n",
       "3           1   Monthly    1995-03-24      NaN       NaT          NaN   \n",
       "4           1   Monthly    1995-03-24      NaN       NaT          NaN   \n",
       "\n",
       "   loan_duration  loan_payments loan_status  order_id  ... a7  a8  a9   a10  \\\n",
       "0            NaN            NaN         NaN   29401.0  ...  2   1   4  65.3   \n",
       "1            NaN            NaN         NaN   29401.0  ...  2   1   4  65.3   \n",
       "2            NaN            NaN         NaN   29401.0  ...  2   1   4  65.3   \n",
       "3            NaN            NaN         NaN   29401.0  ...  2   1   4  65.3   \n",
       "4            NaN            NaN         NaN   29401.0  ...  2   1   4  65.3   \n",
       "\n",
       "    a11   a12   a13  a14     a15   a16  \n",
       "0  8968  2.83  3.35  131  1740.0  1910  \n",
       "1  8968  2.83  3.35  131  1740.0  1910  \n",
       "2  8968  2.83  3.35  131  1740.0  1910  \n",
       "3  8968  2.83  3.35  131  1740.0  1910  \n",
       "4  8968  2.83  3.35  131  1740.0  1910  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6735fb26-42d7-4621-b5ff-d92dd5778e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2243458, 46)\n",
      "account_id                  int64\n",
      "frequency                  object\n",
      "creation_date      datetime64[ns]\n",
      "loan_id                   float64\n",
      "loan_date          datetime64[ns]\n",
      "loan_amount               float64\n",
      "loan_duration             float64\n",
      "loan_payments             float64\n",
      "loan_status                object\n",
      "order_id                  float64\n",
      "bank_to                    object\n",
      "account_to                float64\n",
      "order_amount              float64\n",
      "payment_type               object\n",
      "trans_id                    int64\n",
      "trans_date         datetime64[ns]\n",
      "trans_type                 object\n",
      "operation                  object\n",
      "trans_amount              float64\n",
      "balance                   float64\n",
      "trans_detail               object\n",
      "partner_bank               object\n",
      "partner_account           float64\n",
      "disp_id                     int64\n",
      "client_id                   int64\n",
      "disp_type                  object\n",
      "card_id                   float64\n",
      "card_type                  object\n",
      "card_issued                object\n",
      "birth_number                int64\n",
      "a1                          int64\n",
      "a2                         object\n",
      "a3                         object\n",
      "a4                          int64\n",
      "a5                          int64\n",
      "a6                          int64\n",
      "a7                          int64\n",
      "a8                          int64\n",
      "a9                          int64\n",
      "a10                       float64\n",
      "a11                         int64\n",
      "a12                       float64\n",
      "a13                       float64\n",
      "a14                         int64\n",
      "a15                       float64\n",
      "a16                         int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['account_id', 'frequency', 'creation_date', 'loan_id', 'loan_date',\n",
       "       'loan_amount', 'loan_duration', 'loan_payments', 'loan_status',\n",
       "       'order_id', 'bank_to', 'account_to', 'order_amount', 'payment_type',\n",
       "       'trans_id', 'trans_date', 'trans_type', 'operation', 'trans_amount',\n",
       "       'balance', 'trans_detail', 'partner_bank', 'partner_account', 'disp_id',\n",
       "       'client_id', 'disp_type', 'card_id', 'card_type', 'card_issued',\n",
       "       'birth_number', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'a8', 'a9',\n",
       "       'a10', 'a11', 'a12', 'a13', 'a14', 'a15', 'a16'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.dtypes)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88cbae1f-f851-405a-b38b-8299e25883ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting database\n",
      "Deleted database\n",
      "Creating database\n",
      "Done\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'load_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 30\u001b[0m\n\u001b[1;32m     22\u001b[0m     creation_date \u001b[38;5;241m=\u001b[39m a[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreation_date\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstrftime(DATE_FORMAT_SQL)\n\u001b[1;32m     23\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINSERT INTO Account VALUES (?, ?, ?);\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m         (account_id, a[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency\u001b[39m\u001b[38;5;124m\"\u001b[39m], creation_date)\n\u001b[1;32m     26\u001b[0m     )\n\u001b[1;32m     28\u001b[0m loans \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloan_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdisp_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloan_date\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloan_amount\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloan_duration\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloan_payments\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloan_status\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m---> 30\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mload_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfirst()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m loans\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     32\u001b[0m     loan_id \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/data/lib/python3.11/site-packages/pandas/core/frame.py:8869\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   8867\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 8869\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8872\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8875\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/data/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1278\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1278\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m~/miniconda3/envs/data/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:1009\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1009\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'load_id'"
     ]
    }
   ],
   "source": [
    "# ISO 8601 date\n",
    "# https://www.sqlite.org/lang_datefunc.html\n",
    "DATE_FORMAT_SQL = \"%Y-%m-%d\"\n",
    "\n",
    "\n",
    "# reset db for testing\n",
    "create_db()\n",
    "\n",
    "\n",
    "# todo important stage bankrecords.db in submission\n",
    "\n",
    "con = sqlite3.connect(sqlf)\n",
    "cur = con.cursor()\n",
    "\n",
    "accounts = df.filter(\n",
    "    [\"account_id\", \"frequency\", \"creation_date\"]\n",
    ").groupby(\"account_id\").first()\n",
    "for row in accounts.iterrows():\n",
    "    # todo try df.to_sql()\n",
    "    account_id = row[0]\n",
    "    a = row[1]\n",
    "    creation_date = a[\"creation_date\"].strftime(DATE_FORMAT_SQL)\n",
    "    cur.execute(\n",
    "        \"INSERT INTO Account VALUES (?, ?, ?);\",\n",
    "        (account_id, a[\"frequency\"], creation_date)\n",
    "    )\n",
    "\n",
    "loans = df.filter(\n",
    "    [\"loan_id\", \"disp_id\", \"loan_date\", \"loan_amount\", \"loan_duration\", \"loan_payments\", \"loan_status\"]\n",
    ").groupby(\"load_id\").first()\n",
    "for row in loans.iterrows():\n",
    "    loan_id = row[0]\n",
    "    a = row[1]\n",
    "    loan_date = a[\"loan_date\"].strftime(DATE_FORMAT_SQL)\n",
    "    cur.execute(\n",
    "        \"INSERT INTO Loan VALUES (?, ?, ?, ?, ?, ?, ?);\",\n",
    "        (loan_id, a[\"disp_id\"], loan_date, a[\"loan_amount\"], a[\"loan_duration\"], a[\"loan_payments\"], a[\"loan_status\"])\n",
    "    )\n",
    "\n",
    "cur.close()\n",
    "con.commit()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56000f9f",
   "metadata": {
    "id": "56000f9f"
   },
   "source": [
    "----\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd4f6c6",
   "metadata": {
    "id": "bbd4f6c6"
   },
   "source": [
    "## Task 3: Research Design (25 Marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d4db00",
   "metadata": {
    "id": "26d4db00"
   },
   "source": [
    "Using the database designed in Task 2, design and implement **five** potential modelling solutions to achieve the aim of the Data Intelligence team. You need to provide clear justifications about the techniques selected in the context of the 'problem in hand'. Your design must consist of a combination of inferential statistics, supervised learning algorithms, and unsupervised learning algorithms, and include **at least one** of those techniques. Finally, your modelling solutions should be of sufficient complexity, combining information from multiple tables from the database built in Task 2, as appropriate. Your answer should clearly show the queries made to the database. If amendments are made to the database, the commands should be clearly included in your answer.\n",
    "\n",
    "Your answer should clearly cover the following:\n",
    "* Any assumptions you are making about the given scenario;\n",
    "* Any data processing and data integrity steps you would undertake to make the data fit for purpose;\n",
    "* Which technique(s) you would apply for each solution and why;\n",
    "* An evaluation of the techniques applied in terms of the accuracy of their results (or any other suitable evaluation measure);\n",
    "* Algorithmic parameters should be adequately stated and discussed;\n",
    "* A discussion of ethical considerations arising from the solutions selected.\n",
    "\n",
    "**World Limit**: 500 words. This limit applies only to the explanations. There is no limit on any associated code or figures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VVfHwzLCX_NX",
   "metadata": {
    "id": "VVfHwzLCX_NX"
   },
   "source": [
    "**Write your answer here (text cell(s) to be used, as appropriate)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cc2086",
   "metadata": {
    "id": "a9cc2086"
   },
   "outputs": [],
   "source": [
    "### Write your answer here (code cell(s) to be used, as appropriate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a552f4c6",
   "metadata": {
    "id": "a552f4c6"
   },
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f808a0fa",
   "metadata": {
    "id": "f808a0fa"
   },
   "source": [
    "## Task 4: Experimental Results and Analysis (25 Marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71f250b",
   "metadata": {
    "id": "c71f250b"
   },
   "source": [
    "Given the **five** modelling solutions implemented above, analyse, discuss and present your findings to the key stakeholders of the bank.\n",
    "\n",
    "Your answer should clearly cover the following:\n",
    "* Present your findings in a clear and concise manner;\n",
    "* Discuss your results in the context of the selected solution;\n",
    "* Discuss how these results can help the bank in performing customer risk assessment and establishing customer retention strategies;\n",
    "* Present the limitations (if any) of your solutions in a clear and concise manner.\n",
    "\n",
    "**World Limit**: 500 words. This limit applies only to the explanations. There is no limit on any associated code or figures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sXb02r__Ykgr",
   "metadata": {
    "id": "sXb02r__Ykgr"
   },
   "source": [
    "**Write your answer here (text cell(s) to be used, as appropriate)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521811e9",
   "metadata": {
    "id": "521811e9"
   },
   "outputs": [],
   "source": [
    "### Write your answer here (code cell(s) to be used, as appropriate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dc2a18",
   "metadata": {
    "id": "d2dc2a18"
   },
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728dd77f",
   "metadata": {
    "id": "728dd77f"
   },
   "source": [
    "## Task 5: Conclusion (10 Marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be71ded",
   "metadata": {
    "id": "5be71ded"
   },
   "source": [
    "Given the insights derived from Tasks 1-4, provide a conclusion that clearly covers the following:\n",
    "* A summary of the main points;\n",
    "* A discussion of the significance of your results;\n",
    "* Any recommendation(s) resulting from your analysis;\n",
    "* Any overall ethical considerations arising from the data analysis of this business domain.\n",
    "\n",
    "**World Limit**: 300 words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OmyhUuiqZc70",
   "metadata": {
    "id": "OmyhUuiqZc70"
   },
   "source": [
    "**Write your answer here (text cell(s) to be used, as appropriate)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334be1b5",
   "metadata": {
    "id": "334be1b5"
   },
   "outputs": [],
   "source": [
    "### Write your answer here (code cell(s) to be used, as appropriate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bd1577",
   "metadata": {
    "id": "a1bd1577"
   },
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce07aa2",
   "metadata": {
    "id": "dce07aa2"
   },
   "source": [
    "## Overall Academic Quality (10 Marks)\n",
    "10 marks are allocated for the clarity and cohesiveness of your answers (both text and code) across all tasks with appropriate, relevant and effective analysis and presentation of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9440ef2b",
   "metadata": {
    "id": "9440ef2b"
   },
   "source": [
    "## Deliverables\n",
    "\n",
    "You should submit the following to the submission point on the teaching portal:\n",
    "\n",
    "1. the SQLite database produced in Task 2;\n",
    "2. the completed Jupyter notebook (both .ipynb and HTML files) that also includes the SQL statements (Task 2), the research design and its implementation (Task 3), and the analysis and presentation of your results (Task 4);\n",
    "3. any figures or diagrams that are included in your answers in the Jupyter notebook.\n",
    "\n",
    "For each task where text is required, we have provided guidelines above on the suggested word counts. Exceeding the word count will result in any work beyond the word count being disregarded when assessing."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
