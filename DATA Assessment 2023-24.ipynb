{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "J_8Hl6RhR5Th",
   "metadata": {
    "id": "J_8Hl6RhR5Th"
   },
   "source": [
    "## Department of Computer Science, University of York\n",
    "### DATA: Introduction to Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833fc93b",
   "metadata": {
    "id": "833fc93b"
   },
   "source": [
    "## Task 1: Domain Analysis  (5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RbtRJd18asfN",
   "metadata": {
    "id": "RbtRJd18asfN"
   },
   "source": [
    "Given the business domain and the data overview presented (in the assessment paper), provide a brief description of\n",
    "\n",
    "* the business problem and its significance to the relevant sector;\n",
    "* the link between the business problem and the field of data science;\n",
    "* the main areas of investigation; and\n",
    "* potential ideas and solutions.\n",
    "\n",
    "\n",
    "**Word Limit:** 300 words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LQ_p4Qitu334",
   "metadata": {
    "id": "LQ_p4Qitu334"
   },
   "source": [
    "**Write your answer here (text cell(s) to be used, as appropriate)**\n",
    "\n",
    "The business problem is that this bank's executives aren't making enough money. They only made £3100000000000000 in bonuses last year and it's only reasonable economics to expect this number to double every year forever. We got to make more money, and YOU got to help us! If you need instructions on how to get through the notebook, please check out the enclosed instruction book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "G8kyLn-xXG9O",
   "metadata": {
    "id": "G8kyLn-xXG9O"
   },
   "outputs": [],
   "source": [
    "### Write your answer here (code cell(s) to be used, as appropriate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326757ae",
   "metadata": {
    "id": "326757ae"
   },
   "source": [
    "\n",
    "----\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f0a14c",
   "metadata": {
    "id": "f2f0a14c"
   },
   "source": [
    "## Task 2: Database Design (25 marks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dC2nOMbbU5AG",
   "metadata": {
    "id": "dC2nOMbbU5AG"
   },
   "source": [
    "Having understood the business domain, present a conceptual design in the form of an entity-relationship (ER) model that would be helpful in creating a database for the bank.\n",
    "\n",
    "The bank data currently exists in the form of a csv file called *BankRecords.csv*, provided on VLE (path given in page 5, assessment paper). This file has all the existing records. The table available in the csv file is unnormalised. The information about its different columns is given in Tables 1 and 2 (in the assessment paper).\n",
    "\n",
    "Following the standard principles of database normalisation, normalise the given table (*BankRecords.csv*) to a database schema that has minimum redundancies. Then, using the designed schema, create an SQLite database.\n",
    "\n",
    "Your answer should include the SQL statements needed to accomplish this step. Your submission should also include the created SQLite database file.\n",
    "\n",
    "Your answer should clearly cover the following:\n",
    "* Any assumptions you are making about the given scenario;\n",
    "* The designated keys, existing relationships, and identified functional dependencies;\n",
    "* The steps followed and justifications for the decisions made.\n",
    "\n",
    "**World Limit**: 500 words. This limit applies only to the explanations. There is no limit on any associated code/SQL statements or figures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43203df7",
   "metadata": {
    "id": "43203df7"
   },
   "source": [
    "**Write your answer here (text cell(s) to be used, as appropriate)**\n",
    "\n",
    "# Normal form\n",
    "\n",
    "The data is already in first normal form as there are no composite values, so we can continue to 2NF.\n",
    "\n",
    "This table is clearly not in second normal form. Loan date is dependent on loan ID, name is dependent on client ID, etc. etc. There are a bunch of values that should be primary keys all in the same table. I split up the dataset into eight separate tables intuitively based on the \"Data Overview\" and \"Description of columns\" from the specification. Each unique ID gets its own table.\n",
    "\n",
    "Now in 2NF, I noticed noticed a transitive dependency - I had included dispID, clientID, and accountID together in their relevant tables. I realised clientID and accountID are both just dependent on dispID. Therefore I removed them from all the tables except Dispositon. Finally, we are in third normal form and finished.\n",
    "\n",
    "Reference:\n",
    "- DATA-Lecture4-DatabaseNormalisationAndSQL.pdf\n",
    "- https://en.wikipedia.org/wiki/Database_normalization\n",
    "\n",
    "# ERM\n",
    "For the ERM diagram, see `DATA Essay.jpg`.\n",
    "\n",
    "![ERM Diagram](DATA%20Essay.jpg)\n",
    "\n",
    "Reference:\n",
    "- DATA-Lecture3-RelationalDatabases.pdf\n",
    "- DATA-Practical3Part2 - Mapping ER model to tables - Solution.pdf\n",
    "- https://en.wikipedia.org/wiki/Entity%E2%80%93relationship_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5988039d-a777-44aa-93c3-e05b282f97b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a33ca09c",
   "metadata": {
    "id": "a33ca09c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting database\n",
      "Deleted database\n",
      "Creating database\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "### Write your answer here (code cell(s) to be used, as appropriate)\n",
    "\n",
    "# the following classifier fields could be made integers:\n",
    "#   Account\n",
    "#     statementFrequency\n",
    "#   Loan\n",
    "#     loanStatus\n",
    "#   StandingOrder\n",
    "#     NOT paymentType\n",
    "#   BankTransaction\n",
    "#     transType\n",
    "#     operation\n",
    "#     NOT transDetail\n",
    "#   Disposition\n",
    "#     dispType\n",
    "#   CreditCard\n",
    "#     cardType\n",
    "\n",
    "sql_script_path = Path(\"create_db.sqlite3\")\n",
    "sqlf = Path(\"BankRecords.db\")\n",
    "\n",
    "\n",
    "def create_db():\n",
    "    sql_create = sql_script_path.read_text(encoding=\"utf-8\")\n",
    "    \n",
    "    print(\"Deleting database\")\n",
    "    try:\n",
    "        sqlf.unlink()\n",
    "    except FileNotFoundError:\n",
    "        print(\"Database didn't exist\")\n",
    "    else:\n",
    "        print(\"Deleted database\")\n",
    "    \n",
    "    print(\"Creating database\")\n",
    "    con = sqlite3.connect(sqlf)\n",
    "    with con:\n",
    "        con.executescript(sql_create)\n",
    "    con.close()\n",
    "    print(\"Done\")\n",
    "\n",
    "\n",
    "create_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b603743e-4bce-4109-893c-32f15f5bc65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0690ff0d-59b5-4578-8fb1-0f0f6b1d9b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading csv\n",
      "CPU times: user 6.77 s, sys: 4.14 s, total: 10.9 s\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# load dataframe\n",
    "DATE_FORMAT_CSV = \"%y%m%d\"\n",
    "\n",
    "csvf = Path(\"BankRecords.csv\")\n",
    "\n",
    "print(\"Loading csv\")\n",
    "\n",
    "# could manually convert to datetime after reading\n",
    "# to set the unit to something better for dates than ns\n",
    "# but this is fine\n",
    "date_columns = [\n",
    "    \"creation_date\",\n",
    "    \"loan_date\",\n",
    "    \"trans_date\",\n",
    "    \"card_issued\",\n",
    "]\n",
    "date_formats = {c: DATE_FORMAT_CSV for c in date_columns}\n",
    "date_formats[\"card_issued\"] = f\"{DATE_FORMAT_CSV} 00:00:00\"  # they lied about this one\n",
    "\n",
    "df = pd.read_csv(\n",
    "    csvf,\n",
    "    parse_dates=date_columns,\n",
    "    date_format=date_formats,\n",
    "    low_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f888f528-bf8a-4be8-bf0b-c4802946302e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>frequency</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>loan_id</th>\n",
       "      <th>loan_date</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>loan_duration</th>\n",
       "      <th>loan_payments</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>order_id</th>\n",
       "      <th>...</th>\n",
       "      <th>a7</th>\n",
       "      <th>a8</th>\n",
       "      <th>a9</th>\n",
       "      <th>a10</th>\n",
       "      <th>a11</th>\n",
       "      <th>a12</th>\n",
       "      <th>a13</th>\n",
       "      <th>a14</th>\n",
       "      <th>a15</th>\n",
       "      <th>a16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>1995-03-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29401.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>65.3</td>\n",
       "      <td>8968</td>\n",
       "      <td>2.83</td>\n",
       "      <td>3.35</td>\n",
       "      <td>131</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>1910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>1995-03-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29401.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>65.3</td>\n",
       "      <td>8968</td>\n",
       "      <td>2.83</td>\n",
       "      <td>3.35</td>\n",
       "      <td>131</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>1910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>1995-03-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29401.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>65.3</td>\n",
       "      <td>8968</td>\n",
       "      <td>2.83</td>\n",
       "      <td>3.35</td>\n",
       "      <td>131</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>1910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>1995-03-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29401.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>65.3</td>\n",
       "      <td>8968</td>\n",
       "      <td>2.83</td>\n",
       "      <td>3.35</td>\n",
       "      <td>131</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>1910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>1995-03-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29401.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>65.3</td>\n",
       "      <td>8968</td>\n",
       "      <td>2.83</td>\n",
       "      <td>3.35</td>\n",
       "      <td>131</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>1910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_id frequency creation_date  loan_id loan_date  loan_amount  \\\n",
       "0           1   Monthly    1995-03-24      NaN       NaT          NaN   \n",
       "1           1   Monthly    1995-03-24      NaN       NaT          NaN   \n",
       "2           1   Monthly    1995-03-24      NaN       NaT          NaN   \n",
       "3           1   Monthly    1995-03-24      NaN       NaT          NaN   \n",
       "4           1   Monthly    1995-03-24      NaN       NaT          NaN   \n",
       "\n",
       "   loan_duration  loan_payments loan_status  order_id  ... a7  a8  a9   a10  \\\n",
       "0            NaN            NaN         NaN   29401.0  ...  2   1   4  65.3   \n",
       "1            NaN            NaN         NaN   29401.0  ...  2   1   4  65.3   \n",
       "2            NaN            NaN         NaN   29401.0  ...  2   1   4  65.3   \n",
       "3            NaN            NaN         NaN   29401.0  ...  2   1   4  65.3   \n",
       "4            NaN            NaN         NaN   29401.0  ...  2   1   4  65.3   \n",
       "\n",
       "    a11   a12   a13  a14     a15   a16  \n",
       "0  8968  2.83  3.35  131  1740.0  1910  \n",
       "1  8968  2.83  3.35  131  1740.0  1910  \n",
       "2  8968  2.83  3.35  131  1740.0  1910  \n",
       "3  8968  2.83  3.35  131  1740.0  1910  \n",
       "4  8968  2.83  3.35  131  1740.0  1910  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6735fb26-42d7-4621-b5ff-d92dd5778e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2243458, 46)\n",
      "account_id                  int64\n",
      "frequency                  object\n",
      "creation_date      datetime64[ns]\n",
      "loan_id                   float64\n",
      "loan_date          datetime64[ns]\n",
      "loan_amount               float64\n",
      "loan_duration             float64\n",
      "loan_payments             float64\n",
      "loan_status                object\n",
      "order_id                  float64\n",
      "bank_to                    object\n",
      "account_to                float64\n",
      "order_amount              float64\n",
      "payment_type               object\n",
      "trans_id                    int64\n",
      "trans_date         datetime64[ns]\n",
      "trans_type                 object\n",
      "operation                  object\n",
      "trans_amount              float64\n",
      "balance                   float64\n",
      "trans_detail               object\n",
      "partner_bank               object\n",
      "partner_account           float64\n",
      "disp_id                     int64\n",
      "client_id                   int64\n",
      "disp_type                  object\n",
      "card_id                   float64\n",
      "card_type                  object\n",
      "card_issued        datetime64[ns]\n",
      "birth_number                int64\n",
      "a1                          int64\n",
      "a2                         object\n",
      "a3                         object\n",
      "a4                          int64\n",
      "a5                          int64\n",
      "a6                          int64\n",
      "a7                          int64\n",
      "a8                          int64\n",
      "a9                          int64\n",
      "a10                       float64\n",
      "a11                         int64\n",
      "a12                       float64\n",
      "a13                       float64\n",
      "a14                         int64\n",
      "a15                       float64\n",
      "a16                         int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['account_id', 'frequency', 'creation_date', 'loan_id', 'loan_date',\n",
       "       'loan_amount', 'loan_duration', 'loan_payments', 'loan_status',\n",
       "       'order_id', 'bank_to', 'account_to', 'order_amount', 'payment_type',\n",
       "       'trans_id', 'trans_date', 'trans_type', 'operation', 'trans_amount',\n",
       "       'balance', 'trans_detail', 'partner_bank', 'partner_account', 'disp_id',\n",
       "       'client_id', 'disp_type', 'card_id', 'card_type', 'card_issued',\n",
       "       'birth_number', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'a8', 'a9',\n",
       "       'a10', 'a11', 'a12', 'a13', 'a14', 'a15', 'a16'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that some columns we would expect to be int are float instead\n",
    "# because int can't be NaN but float can\n",
    "print(df.shape)\n",
    "print(df.dtypes)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bce34d56-5161-47db-b15c-b5eb961f9b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         account_id frequency creation_date  loan_id  loan_date  loan_amount  \\\n",
      "2241480       11359   Monthly    1994-10-01   7305.0 1996-08-06      54024.0   \n",
      "2241481       11359   Monthly    1994-10-01   7305.0 1996-08-06      54024.0   \n",
      "2241482       11359   Monthly    1994-10-01   7305.0 1996-08-06      54024.0   \n",
      "2241483       11359   Monthly    1994-10-01   7305.0 1996-08-06      54024.0   \n",
      "2241484       11359   Monthly    1994-10-01   7305.0 1996-08-06      54024.0   \n",
      "\n",
      "         loan_duration  loan_payments loan_status  order_id bank_to  \\\n",
      "2241480           12.0         4502.0           A   46329.0      OP   \n",
      "2241481           12.0         4502.0           A   46329.0      OP   \n",
      "2241482           12.0         4502.0           A   46329.0      OP   \n",
      "2241483           12.0         4502.0           A   46329.0      OP   \n",
      "2241484           12.0         4502.0           A   46329.0      OP   \n",
      "\n",
      "         account_to  order_amount payment_type  trans_id trans_date  \\\n",
      "2241480  33080721.0        4518.0    Household   3423128 1998-12-11   \n",
      "2241481  33080721.0        4518.0    Household   3423093 1998-12-11   \n",
      "2241482  33080721.0        4518.0    Household   3422913 1998-12-14   \n",
      "2241483  33080721.0        4518.0    Household   3422973 1998-12-21   \n",
      "2241484  33080721.0        4518.0    Household   3529998 1998-12-31   \n",
      "\n",
      "         trans_type                     operation  trans_amount  balance  \\\n",
      "2241480  Withdrawal        Credit card withdrawal        1800.0  38550.8   \n",
      "2241481  Withdrawal    Remittance to another bank         254.0  38296.8   \n",
      "2241482      Credit  Collection from another bank       40521.0  78817.8   \n",
      "2241483  Withdrawal            Withdrawal in cash        3900.0  74917.8   \n",
      "2241484      Credit                           NaN         282.6  75200.4   \n",
      "\n",
      "              trans_detail partner_bank  partner_account  disp_id  client_id  \\\n",
      "2241480                NaN          NaN              0.0    13660      13968   \n",
      "2241481                NaN           AB       90330576.0    13660      13968   \n",
      "2241482                NaN           MN       87391823.0    13660      13968   \n",
      "2241483                NaN          NaN              0.0    13660      13968   \n",
      "2241484  Interest credited          NaN              NaN    13660      13968   \n",
      "\n",
      "        disp_type  card_id card_type card_issued  birth_number  a1        a2  \\\n",
      "2241480     OWNER   1247.0   classic  1995-06-13        680413  61  Swindon    \n",
      "2241481     OWNER   1247.0   classic  1995-06-13        680413  61  Swindon    \n",
      "2241482     OWNER   1247.0   classic  1995-06-13        680413  61  Swindon    \n",
      "2241483     OWNER   1247.0   classic  1995-06-13        680413  61  Swindon    \n",
      "2241484     OWNER   1247.0   classic  1995-06-13        680413  61  Swindon    \n",
      "\n",
      "                a3      a4   a5  a6  a7  a8  a9   a10   a11   a12   a13  a14  \\\n",
      "2241480  Wiltshire  117897  139  28   5   1   6  53.8  8814  4.76  5.74  107   \n",
      "2241481  Wiltshire  117897  139  28   5   1   6  53.8  8814  4.76  5.74  107   \n",
      "2241482  Wiltshire  117897  139  28   5   1   6  53.8  8814  4.76  5.74  107   \n",
      "2241483  Wiltshire  117897  139  28   5   1   6  53.8  8814  4.76  5.74  107   \n",
      "2241484  Wiltshire  117897  139  28   5   1   6  53.8  8814  4.76  5.74  107   \n",
      "\n",
      "            a15   a16  \n",
      "2241480  2112.0  2059  \n",
      "2241481  2112.0  2059  \n",
      "2241482  2112.0  2059  \n",
      "2241483  2112.0  2059  \n",
      "2241484  2112.0  2059  \n"
     ]
    }
   ],
   "source": [
    "x = \"loan_id\"\n",
    "df[(df[x] % 1 != 0) & df[x].notna()]\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "print(df[df[\"trans_id\"].notna() & df[\"card_id\"].notna()].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06acb02a-0b56-4f02-81a1-103fedc6d953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creation_date 0\n",
      "loan_date 0\n",
      "trans_date 0\n",
      "card_issued 0\n"
     ]
    }
   ],
   "source": [
    "# since a 2-digit year is ambiguous we have to check this works fine\n",
    "# python's datetime pivot year is 1970\n",
    "# so we can verify all the years are between 70 and 99 like so:\n",
    "for c in date_columns:\n",
    "    print(c, sum(df[c] > pd.Timestamp(year=2000, month=1, day=1)))\n",
    "\n",
    "# therefore, in the special parsing we do for birth_number\n",
    "# we can assume all dates lie in the decade 1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88cbae1f-f851-405a-b38b-8299e25883ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting database\n",
      "Deleted database\n",
      "Creating database\n",
      "Done\n",
      "Inserting data\n",
      "Inserting data complete\n",
      "CPU times: user 9.27 s, sys: 673 ms, total: 9.95 s\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# ISO 8601 date\n",
    "# https://www.sqlite.org/lang_datefunc.html\n",
    "DATE_FORMAT_SQL = \"%Y-%m-%d\"\n",
    "\n",
    "\n",
    "# reset db for testing\n",
    "create_db()\n",
    "\n",
    "\n",
    "def filter_df(columns: list[str]):\n",
    "    return df.filter(columns).groupby(columns[0]).first()\n",
    "\n",
    "\n",
    "print(\"Inserting data\")\n",
    "con = sqlite3.connect(sqlf)\n",
    "cur = con.cursor()\n",
    "\n",
    "accounts = filter_df(\n",
    "    [\"account_id\", \"frequency\", \"creation_date\"]\n",
    ")\n",
    "# no inplace option for this 3':\n",
    "accounts[\"creation_date\"] = accounts[\"creation_date\"].dt.strftime(DATE_FORMAT_SQL)\n",
    "cur.executemany(\n",
    "    \"INSERT INTO Account VALUES (?, ?, ?);\",\n",
    "    accounts.itertuples()\n",
    ")\n",
    "\n",
    "loans = filter_df(\n",
    "    [\"loan_id\", \"disp_id\", \"loan_date\", \"loan_amount\", \"loan_duration\", \"loan_payments\", \"loan_status\"]\n",
    ")\n",
    "loans[\"loan_date\"] = loans[\"loan_date\"].dt.strftime(DATE_FORMAT_SQL)\n",
    "cur.executemany(\n",
    "    \"INSERT INTO Loan VALUES (?, ?, ?, ?, ?, ?, ?);\",\n",
    "    loans.itertuples()\n",
    ")\n",
    "\n",
    "standing_orders = filter_df(\n",
    "    [\"order_id\", \"disp_id\", \"bank_to\", \"account_to\", \"order_amount\", \"payment_type\"]\n",
    ")\n",
    "cur.executemany(\n",
    "    \"INSERT INTO StandingOrder VALUES (?, ?, ?, ?, ?, ?);\",\n",
    "    standing_orders.itertuples()\n",
    ")\n",
    "\n",
    "transactions = filter_df(\n",
    "    [\n",
    "        \"trans_id\", \"disp_id\",\n",
    "        \"trans_date\", \"trans_type\", \"operation\", \"trans_amount\", \"balance\", \"trans_detail\", \"partner_bank\", \"partner_account\",\n",
    "    ]\n",
    ")\n",
    "transactions[\"trans_date\"] = transactions[\"trans_date\"].dt.strftime(DATE_FORMAT_SQL)\n",
    "cur.executemany(\n",
    "    \"INSERT INTO BankTransaction VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?);\",\n",
    "    transactions.itertuples()\n",
    ")\n",
    "\n",
    "clients = filter_df(\n",
    "    [\"client_id\", \"a1\", \"birth_number\"]\n",
    ")\n",
    "# separating birth number into relevant columns\n",
    "# could also do this as string operations\n",
    "# bool mask of all rows with MM+50\n",
    "clients[\"gender\"] = ((clients[\"birth_number\"] // 100) % 100) > 12\n",
    "# remove offset\n",
    "# 100(x + 50) = 100x + 5000\n",
    "clients.loc[clients[\"gender\"], \"birth_number\"] -= 5000\n",
    "# parse date\n",
    "clients[\"birth_number\"] += 19000000  # see above cell\n",
    "clients[\"birth_number\"] = pd.to_datetime(clients[\"birth_number\"], format=\"%Y%m%d\")\n",
    "clients[\"birth_number\"] = clients[\"birth_number\"].dt.strftime(DATE_FORMAT_SQL)\n",
    "cur.executemany(\n",
    "    \"INSERT INTO Client VALUES (?, ?, ?, ?);\",\n",
    "    clients.itertuples()\n",
    ")\n",
    "\n",
    "dispositions = filter_df(\n",
    "    [\"disp_id\", \"account_id\", \"client_id\", \"disp_type\"]\n",
    ")\n",
    "# dispo elysium\n",
    "cur.executemany(\n",
    "    \"INSERT INTO Disposition VALUES (?, ?, ?, ?);\",\n",
    "    dispositions.itertuples()\n",
    ")\n",
    "\n",
    "credit_cars = filter_df(\n",
    "    [\"card_id\", \"disp_id\", \"card_type\", \"card_issued\"]\n",
    ")\n",
    "credit_cars[\"card_issued\"] = credit_cars[\"card_issued\"].dt.strftime(DATE_FORMAT_SQL)\n",
    "cur.executemany(\n",
    "    \"INSERT INTO CreditCard VALUES (?, ?, ?, ?);\",\n",
    "    credit_cars.itertuples()\n",
    ")\n",
    "\n",
    "cities = filter_df(\n",
    "    [f\"a{i}\" for i in range(1, 16+1)]\n",
    ")\n",
    "cur.executemany(\n",
    "    \"INSERT INTO City VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?);\",\n",
    "    cities.itertuples()\n",
    ")\n",
    "\n",
    "cur.close()\n",
    "con.commit()\n",
    "con.close()\n",
    "print(\"Inserting data complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56000f9f",
   "metadata": {
    "id": "56000f9f",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "----\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd4f6c6",
   "metadata": {
    "id": "bbd4f6c6"
   },
   "source": [
    "## Task 3: Research Design (25 Marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d4db00",
   "metadata": {
    "id": "26d4db00"
   },
   "source": [
    "Using the database designed in Task 2, design and implement **five** potential modelling solutions to achieve the aim of the Data Intelligence team. You need to provide clear justifications about the techniques selected in the context of the 'problem in hand'. Your design must consist of a combination of inferential statistics, supervised learning algorithms, and unsupervised learning algorithms, and include **at least one** of those techniques. Finally, your modelling solutions should be of sufficient complexity, combining information from multiple tables from the database built in Task 2, as appropriate. Your answer should clearly show the queries made to the database. If amendments are made to the database, the commands should be clearly included in your answer.\n",
    "\n",
    "Your answer should clearly cover the following:\n",
    "* Any assumptions you are making about the given scenario;\n",
    "* Any data processing and data integrity steps you would undertake to make the data fit for purpose;\n",
    "* Which technique(s) you would apply for each solution and why;\n",
    "* An evaluation of the techniques applied in terms of the accuracy of their results (or any other suitable evaluation measure);\n",
    "* Algorithmic parameters should be adequately stated and discussed;\n",
    "* A discussion of ethical considerations arising from the solutions selected.\n",
    "\n",
    "**World Limit**: 500 words. This limit applies only to the explanations. There is no limit on any associated code or figures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VVfHwzLCX_NX",
   "metadata": {
    "id": "VVfHwzLCX_NX"
   },
   "source": [
    "**Write your answer here (text cell(s) to be used, as appropriate)**\n",
    "\n",
    "techniques\n",
    "1. inferential - standard distribution and hypothesis testing\n",
    "2. supervised - linear regression (simple, multiple, polynomial)\n",
    "    - https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html\n",
    "3. supervised - decision tree (classification)\n",
    "4. unsupervised - clustering (classification)\n",
    "\n",
    "- google \"what does a bank want\" \"how do banks make money\"\n",
    "- could it be they've hidden a puzzle in the data? something specific we're intended to find?\n",
    "\n",
    "suggestions from paper\n",
    "- customer risk assessment\n",
    "- customer retention scheme\n",
    "\n",
    "check if any disponent is involved in other tables, not owner\n",
    "see if I need to include cardID in BankTransaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cc2086",
   "metadata": {
    "id": "a9cc2086"
   },
   "outputs": [],
   "source": [
    "### Write your answer here (code cell(s) to be used, as appropriate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a552f4c6",
   "metadata": {
    "id": "a552f4c6"
   },
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f808a0fa",
   "metadata": {
    "id": "f808a0fa"
   },
   "source": [
    "## Task 4: Experimental Results and Analysis (25 Marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71f250b",
   "metadata": {
    "id": "c71f250b"
   },
   "source": [
    "Given the **five** modelling solutions implemented above, analyse, discuss and present your findings to the key stakeholders of the bank.\n",
    "\n",
    "Your answer should clearly cover the following:\n",
    "* Present your findings in a clear and concise manner;\n",
    "* Discuss your results in the context of the selected solution;\n",
    "* Discuss how these results can help the bank in performing customer risk assessment and establishing customer retention strategies;\n",
    "* Present the limitations (if any) of your solutions in a clear and concise manner.\n",
    "\n",
    "**World Limit**: 500 words. This limit applies only to the explanations. There is no limit on any associated code or figures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sXb02r__Ykgr",
   "metadata": {
    "id": "sXb02r__Ykgr"
   },
   "source": [
    "**Write your answer here (text cell(s) to be used, as appropriate)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521811e9",
   "metadata": {
    "id": "521811e9"
   },
   "outputs": [],
   "source": [
    "### Write your answer here (code cell(s) to be used, as appropriate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dc2a18",
   "metadata": {
    "id": "d2dc2a18"
   },
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728dd77f",
   "metadata": {
    "id": "728dd77f"
   },
   "source": [
    "## Task 5: Conclusion (10 Marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be71ded",
   "metadata": {
    "id": "5be71ded"
   },
   "source": [
    "Given the insights derived from Tasks 1-4, provide a conclusion that clearly covers the following:\n",
    "* A summary of the main points;\n",
    "* A discussion of the significance of your results;\n",
    "* Any recommendation(s) resulting from your analysis;\n",
    "* Any overall ethical considerations arising from the data analysis of this business domain.\n",
    "\n",
    "**World Limit**: 300 words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OmyhUuiqZc70",
   "metadata": {
    "id": "OmyhUuiqZc70"
   },
   "source": [
    "**Write your answer here (text cell(s) to be used, as appropriate)**\n",
    "\n",
    "In summary, discombobulate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334be1b5",
   "metadata": {
    "id": "334be1b5"
   },
   "outputs": [],
   "source": [
    "### Write your answer here (code cell(s) to be used, as appropriate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bd1577",
   "metadata": {
    "id": "a1bd1577"
   },
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce07aa2",
   "metadata": {
    "id": "dce07aa2"
   },
   "source": [
    "## Overall Academic Quality (10 Marks)\n",
    "10 marks are allocated for the clarity and cohesiveness of your answers (both text and code) across all tasks with appropriate, relevant and effective analysis and presentation of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9440ef2b",
   "metadata": {
    "id": "9440ef2b"
   },
   "source": [
    "## Deliverables\n",
    "\n",
    "You should submit the following to the submission point on the teaching portal:\n",
    "\n",
    "1. the SQLite database produced in Task 2;\n",
    "2. the completed Jupyter notebook (both .ipynb and HTML files) that also includes the SQL statements (Task 2), the research design and its implementation (Task 3), and the analysis and presentation of your results (Task 4);\n",
    "3. any figures or diagrams that are included in your answers in the Jupyter notebook.\n",
    "\n",
    "For each task where text is required, we have provided guidelines above on the suggested word counts. Exceeding the word count will result in any work beyond the word count being disregarded when assessing."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
