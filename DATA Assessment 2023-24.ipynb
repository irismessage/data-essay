{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "J_8Hl6RhR5Th",
   "metadata": {
    "id": "J_8Hl6RhR5Th"
   },
   "source": [
    "## Department of Computer Science, University of York\n",
    "### DATA: Introduction to Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833fc93b",
   "metadata": {
    "id": "833fc93b"
   },
   "source": [
    "## Task 1: Domain Analysis  (5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RbtRJd18asfN",
   "metadata": {
    "id": "RbtRJd18asfN"
   },
   "source": [
    "Given the business domain and the data overview presented (in the assessment paper), provide a brief description of\n",
    "\n",
    "* the business problem and its significance to the relevant sector;\n",
    "* the link between the business problem and the field of data science;\n",
    "* the main areas of investigation; and\n",
    "* potential ideas and solutions.\n",
    "\n",
    "\n",
    "**Word Limit:** 300 words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LQ_p4Qitu334",
   "metadata": {
    "id": "LQ_p4Qitu334"
   },
   "source": [
    "**Write your answer here (text cell(s) to be used, as appropriate)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "G8kyLn-xXG9O",
   "metadata": {
    "id": "G8kyLn-xXG9O"
   },
   "outputs": [],
   "source": [
    "### Write your answer here (code cell(s) to be used, as appropriate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326757ae",
   "metadata": {
    "id": "326757ae"
   },
   "source": [
    "\n",
    "----\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f0a14c",
   "metadata": {
    "id": "f2f0a14c"
   },
   "source": [
    "## Task 2: Database Design (25 marks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dC2nOMbbU5AG",
   "metadata": {
    "id": "dC2nOMbbU5AG"
   },
   "source": [
    "Having understood the business domain, present a conceptual design in the form of an entity-relationship (ER) model that would be helpful in creating a database for the bank.\n",
    "\n",
    "The bank data currently exists in the form of a csv file called *BankRecords.csv*, provided on VLE (path given in page 5, assessment paper). This file has all the existing records. The table available in the csv file is unnormalised. The information about its different columns is given in Tables 1 and 2 (in the assessment paper).\n",
    "\n",
    "Following the standard principles of database normalisation, normalise the given table (*BankRecords.csv*) to a database schema that has minimum redundancies. Then, using the designed schema, create an SQLite database.\n",
    "\n",
    "Your answer should include the SQL statements needed to accomplish this step. Your submission should also include the created SQLite database file.\n",
    "\n",
    "Your answer should clearly cover the following:\n",
    "* Any assumptions you are making about the given scenario;\n",
    "* The designated keys, existing relationships, and identified functional dependencies;\n",
    "* The steps followed and justifications for the decisions made.\n",
    "\n",
    "**World Limit**: 500 words. This limit applies only to the explanations. There is no limit on any associated code/SQL statements or figures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43203df7",
   "metadata": {
    "id": "43203df7"
   },
   "source": [
    "**Write your answer here (text cell(s) to be used, as appropriate)**\n",
    "\n",
    "For the ERM diagram, see `DATA Essay.jpg`.\n",
    "\n",
    "![ERM Diagram](DATA Essay.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5988039d-a777-44aa-93c3-e05b282f97b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a33ca09c",
   "metadata": {
    "id": "a33ca09c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting database\n",
      "Deleted database\n",
      "Creating database\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "### Write your answer here (code cell(s) to be used, as appropriate)\n",
    "\n",
    "# todo not nulls\n",
    "# todo constraints\n",
    "# todo the following classifier fields could be made integers:\n",
    "#     statementFrequency\n",
    "#     loanStatus\n",
    "#     transType\n",
    "#     dispType\n",
    "#     cardType\n",
    "\n",
    "sql_create = \"\"\"\n",
    "CREATE TABLE Account (\n",
    "    accountID INTEGER PRIMARY KEY,\n",
    "    statementFrequency TEXT,  -- frequency\n",
    "    creationDate TEXT\n",
    ");\n",
    "CREATE TABLE Loan (\n",
    "    loanID INTEGER PRIMARY KEY,\n",
    "    dispID INTEGER,\n",
    "    loanDate TEXT,\n",
    "    loanAmount REAL,\n",
    "    loanDuration INTEGER,\n",
    "    loanPayments INTEGER,\n",
    "    loanStatus TEXT,\n",
    "    FOREIGN KEY (dispID) REFERENCES Disposition(dispID)\n",
    ");\n",
    "CREATE TABLE StandingOrder (\n",
    "    orderID INTEGER PRIMARY KEY,\n",
    "    dispID INTEGER,\n",
    "    bankTo STRING,\n",
    "    accountTo INTEGER,\n",
    "    orderAmount REAL,\n",
    "    paymentType STRING,\n",
    "    FOREIGN KEY (dispID) REFERENCES Disposition(dispID)\n",
    ");\n",
    "CREATE TABLE BankTransaction (  -- Transaction is a reserved word\n",
    "    transID INTEGER PRIMARY KEY,\n",
    "    dispID INTEGER,\n",
    "    transDate TEXT,\n",
    "    transType TEXT,\n",
    "    operation TEXT,\n",
    "    transAmount REAL,\n",
    "    balance REAL,\n",
    "    transDetail TEXT,\n",
    "    partnerBank TEXT,\n",
    "    partnerAccount INTEGER,\n",
    "    FOREIGN KEY (dispID) REFERENCES Disposition(dispID)\n",
    ");\n",
    "CREATE TABLE Client (\n",
    "    clientID INTEGER PRIMARY KEY,\n",
    "    cityID INTEGER,  -- a1\n",
    "    birthDate TEXT,  -- birth_number\n",
    "    gender INTEGER,  -- birth_number\n",
    "    FOREIGN KEY (cityID) REFERENCES City(cityID)\n",
    ");\n",
    "CREATE TABLE Disposition (\n",
    "    dispID INTEGER PRIMARY KEY,\n",
    "    accountID INTEGER,\n",
    "    clientID INTEGER,\n",
    "    dispType TEXT,\n",
    "    FOREIGN KEY (accountID) REFERENCES Account(accountID),\n",
    "    FOREIGN KEY (clientID) REFERENCES Client(clientID)\n",
    ");\n",
    "CREATE TABLE CreditCard (\n",
    "    cardID INTEGER PRIMARY KEY,\n",
    "    dispID INTEGER,\n",
    "    cardType TEXT,\n",
    "    cardIssued TEXT,\n",
    "    FOREIGN KEY (dispID) REFERENCES Disposition(dispID)\n",
    ");\n",
    "CREATE TABLE City (\n",
    "    cityID INTEGER PRIMARY KEY,  -- a1\n",
    "    cityName TEXT,\n",
    "    region TEXT,\n",
    "    inhabitants INTEGER,\n",
    "    muns0 INTEGER,\n",
    "    muns500 INTEGER,\n",
    "    muns2000 INTEGER,\n",
    "    muns10000 INTEGER,\n",
    "    noAreas INTEGER,\n",
    "    ratioUrban REAL,\n",
    "    avgSalary REAL,\n",
    "    unemployment1995 REAL,\n",
    "    unemployment1996 REAL,\n",
    "    entrepeneurs INTEGER,\n",
    "    crimes1995 INTEGER,\n",
    "    crimes1996 INTEGER  -- a16\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "sqlf = Path(\"BankRecords.db\")\n",
    "\n",
    "\n",
    "def create_db():\n",
    "    print(\"Deleting database\")\n",
    "    try:\n",
    "        sqlf.unlink()\n",
    "    except FileNotFoundError:\n",
    "        print(\"Database didn't exist\")\n",
    "    else:\n",
    "        print(\"Deleted database\")\n",
    "    \n",
    "    print(\"Creating database\")\n",
    "    con = sqlite3.connect(sqlf)\n",
    "    with con:\n",
    "        con.executescript(sql_create)\n",
    "    con.close()\n",
    "    print(\"Done\")\n",
    "\n",
    "create_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b603743e-4bce-4109-893c-32f15f5bc65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0690ff0d-59b5-4578-8fb1-0f0f6b1d9b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading csv\n",
      "CPU times: user 6.78 s, sys: 7.73 s, total: 14.5 s\n",
      "Wall time: 15.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# load dataframe\n",
    "DATE_FORMAT_CSV = \"%y%m%d\"\n",
    "\n",
    "csvf = Path(\"BankRecords.csv\")\n",
    "\n",
    "print(\"Loading csv\")\n",
    "\n",
    "# could manually convert to datetime after reading\n",
    "# to set the unit to something better for dates than ns\n",
    "# but this is fine\n",
    "date_columns = [\n",
    "    \"creation_date\",\n",
    "    \"loan_date\",\n",
    "    \"trans_date\",\n",
    "    \"card_issued\",\n",
    "]\n",
    "date_formats = {c: DATE_FORMAT_CSV for c in date_columns}\n",
    "date_formats[\"card_issued\"] = f\"{DATE_FORMAT_CSV} 00:00:00\"  # they lied about this one\n",
    "\n",
    "df = pd.read_csv(\n",
    "    csvf,\n",
    "    parse_dates=date_columns,\n",
    "    date_format=date_formats,\n",
    "    low_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f888f528-bf8a-4be8-bf0b-c4802946302e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>frequency</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>loan_id</th>\n",
       "      <th>loan_date</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>loan_duration</th>\n",
       "      <th>loan_payments</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>order_id</th>\n",
       "      <th>...</th>\n",
       "      <th>a7</th>\n",
       "      <th>a8</th>\n",
       "      <th>a9</th>\n",
       "      <th>a10</th>\n",
       "      <th>a11</th>\n",
       "      <th>a12</th>\n",
       "      <th>a13</th>\n",
       "      <th>a14</th>\n",
       "      <th>a15</th>\n",
       "      <th>a16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>1995-03-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29401.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>65.3</td>\n",
       "      <td>8968</td>\n",
       "      <td>2.83</td>\n",
       "      <td>3.35</td>\n",
       "      <td>131</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>1910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>1995-03-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29401.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>65.3</td>\n",
       "      <td>8968</td>\n",
       "      <td>2.83</td>\n",
       "      <td>3.35</td>\n",
       "      <td>131</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>1910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>1995-03-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29401.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>65.3</td>\n",
       "      <td>8968</td>\n",
       "      <td>2.83</td>\n",
       "      <td>3.35</td>\n",
       "      <td>131</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>1910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>1995-03-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29401.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>65.3</td>\n",
       "      <td>8968</td>\n",
       "      <td>2.83</td>\n",
       "      <td>3.35</td>\n",
       "      <td>131</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>1910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>1995-03-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29401.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>65.3</td>\n",
       "      <td>8968</td>\n",
       "      <td>2.83</td>\n",
       "      <td>3.35</td>\n",
       "      <td>131</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>1910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_id frequency creation_date  loan_id loan_date  loan_amount  \\\n",
       "0           1   Monthly    1995-03-24      NaN       NaT          NaN   \n",
       "1           1   Monthly    1995-03-24      NaN       NaT          NaN   \n",
       "2           1   Monthly    1995-03-24      NaN       NaT          NaN   \n",
       "3           1   Monthly    1995-03-24      NaN       NaT          NaN   \n",
       "4           1   Monthly    1995-03-24      NaN       NaT          NaN   \n",
       "\n",
       "   loan_duration  loan_payments loan_status  order_id  ... a7  a8  a9   a10  \\\n",
       "0            NaN            NaN         NaN   29401.0  ...  2   1   4  65.3   \n",
       "1            NaN            NaN         NaN   29401.0  ...  2   1   4  65.3   \n",
       "2            NaN            NaN         NaN   29401.0  ...  2   1   4  65.3   \n",
       "3            NaN            NaN         NaN   29401.0  ...  2   1   4  65.3   \n",
       "4            NaN            NaN         NaN   29401.0  ...  2   1   4  65.3   \n",
       "\n",
       "    a11   a12   a13  a14     a15   a16  \n",
       "0  8968  2.83  3.35  131  1740.0  1910  \n",
       "1  8968  2.83  3.35  131  1740.0  1910  \n",
       "2  8968  2.83  3.35  131  1740.0  1910  \n",
       "3  8968  2.83  3.35  131  1740.0  1910  \n",
       "4  8968  2.83  3.35  131  1740.0  1910  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6735fb26-42d7-4621-b5ff-d92dd5778e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2243458, 46)\n",
      "account_id                  int64\n",
      "frequency                  object\n",
      "creation_date      datetime64[ns]\n",
      "loan_id                   float64\n",
      "loan_date          datetime64[ns]\n",
      "loan_amount               float64\n",
      "loan_duration             float64\n",
      "loan_payments             float64\n",
      "loan_status                object\n",
      "order_id                  float64\n",
      "bank_to                    object\n",
      "account_to                float64\n",
      "order_amount              float64\n",
      "payment_type               object\n",
      "trans_id                    int64\n",
      "trans_date         datetime64[ns]\n",
      "trans_type                 object\n",
      "operation                  object\n",
      "trans_amount              float64\n",
      "balance                   float64\n",
      "trans_detail               object\n",
      "partner_bank               object\n",
      "partner_account           float64\n",
      "disp_id                     int64\n",
      "client_id                   int64\n",
      "disp_type                  object\n",
      "card_id                   float64\n",
      "card_type                  object\n",
      "card_issued        datetime64[ns]\n",
      "birth_number                int64\n",
      "a1                          int64\n",
      "a2                         object\n",
      "a3                         object\n",
      "a4                          int64\n",
      "a5                          int64\n",
      "a6                          int64\n",
      "a7                          int64\n",
      "a8                          int64\n",
      "a9                          int64\n",
      "a10                       float64\n",
      "a11                         int64\n",
      "a12                       float64\n",
      "a13                       float64\n",
      "a14                         int64\n",
      "a15                       float64\n",
      "a16                         int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['account_id', 'frequency', 'creation_date', 'loan_id', 'loan_date',\n",
       "       'loan_amount', 'loan_duration', 'loan_payments', 'loan_status',\n",
       "       'order_id', 'bank_to', 'account_to', 'order_amount', 'payment_type',\n",
       "       'trans_id', 'trans_date', 'trans_type', 'operation', 'trans_amount',\n",
       "       'balance', 'trans_detail', 'partner_bank', 'partner_account', 'disp_id',\n",
       "       'client_id', 'disp_type', 'card_id', 'card_type', 'card_issued',\n",
       "       'birth_number', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'a8', 'a9',\n",
       "       'a10', 'a11', 'a12', 'a13', 'a14', 'a15', 'a16'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.dtypes)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "06acb02a-0b56-4f02-81a1-103fedc6d953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creation_date 0\n",
      "loan_date 0\n",
      "trans_date 0\n",
      "card_issued 0\n"
     ]
    }
   ],
   "source": [
    "# since a 2-digit year is ambiguous we have to check this works fine\n",
    "# python's datetime pivot year is 1970\n",
    "# so we can verify all the years are between 70 and 99 like so:\n",
    "for c in date_columns:\n",
    "    print(c, sum(df[c] > pd.Timestamp(year=2000, month=1, day=1)))\n",
    "\n",
    "# therefore, in the special parsing we do for birth_number\n",
    "# we can assume all dates lie in the decade 1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "88cbae1f-f851-405a-b38b-8299e25883ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting database\n",
      "Deleted database\n",
      "Creating database\n",
      "Done\n",
      "Inserting data\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unconverted data remains when parsing with format \"%y%m%d\": \"213\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:65\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/data/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1112\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[1;32m   1111\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1112\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1113\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[0;32m~/miniconda3/envs/data/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:488\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64ns(\n\u001b[1;32m    491\u001b[0m     arg,\n\u001b[1;32m    492\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    496\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    497\u001b[0m )\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/data/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:519\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[1;32m    509\u001b[0m     arg,\n\u001b[1;32m    510\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    514\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    515\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[1;32m    516\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     result, timezones \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m tz \u001b[38;5;129;01min\u001b[39;00m timezones):\n\u001b[1;32m    521\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _return_parsed_timezone_results(result, timezones, utc, name)\n",
      "File \u001b[0;32mstrptime.pyx:534\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:359\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unconverted data remains when parsing with format \"%y%m%d\": \"213\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# ISO 8601 date\n",
    "# https://www.sqlite.org/lang_datefunc.html\n",
    "DATE_FORMAT_SQL = \"%Y-%m-%d\"\n",
    "\n",
    "\n",
    "# reset db for testing\n",
    "create_db()\n",
    "\n",
    "\n",
    "def filter_df(columns: list[str]):\n",
    "    return df.filter(columns).groupby(columns[0]).first()\n",
    "\n",
    "\n",
    "print(\"Inserting data\")\n",
    "con = sqlite3.connect(sqlf)\n",
    "cur = con.cursor()\n",
    "\n",
    "accounts = filter_df(\n",
    "    [\"account_id\", \"frequency\", \"creation_date\"]\n",
    ")\n",
    "# no inplace option for this 3':\n",
    "accounts[\"creation_date\"] = accounts[\"creation_date\"].dt.strftime(DATE_FORMAT_SQL)\n",
    "cur.executemany(\n",
    "    \"INSERT INTO Account VALUES (?, ?, ?);\",\n",
    "    accounts.itertuples()\n",
    ")\n",
    "\n",
    "loans = filter_df(\n",
    "    [\"loan_id\", \"disp_id\", \"loan_date\", \"loan_amount\", \"loan_duration\", \"loan_payments\", \"loan_status\"]\n",
    ")\n",
    "loans[\"loan_date\"] = loans[\"loan_date\"].dt.strftime(DATE_FORMAT_SQL)\n",
    "cur.executemany(\n",
    "    \"INSERT INTO Loan VALUES (?, ?, ?, ?, ?, ?, ?);\",\n",
    "    loans.itertuples()\n",
    ")\n",
    "\n",
    "standing_orders = filter_df(\n",
    "    [\"order_id\", \"disp_id\", \"bank_to\", \"account_to\", \"order_amount\", \"payment_type\"]\n",
    ")\n",
    "cur.executemany(\n",
    "    \"INSERT INTO StandingOrder VALUES (?, ?, ?, ?, ?, ?);\",\n",
    "    standing_orders.itertuples()\n",
    ")\n",
    "\n",
    "transactions = filter_df(\n",
    "    [\"trans_id\", \"disp_id\", \"trans_date\", \"trans_type\", \"operation\", \"trans_amount\", \"balance\", \"trans_detail\", \"partner_bank\", \"partner_account\"]\n",
    ")\n",
    "transactions[\"trans_date\"] = transactions[\"trans_date\"].dt.strftime(DATE_FORMAT_SQL)\n",
    "cur.executemany(\n",
    "    \"INSERT INTO BankTransaction VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?);\",\n",
    "    transactions.itertuples()\n",
    ")\n",
    "con.commit()  # particularly large one\n",
    "\n",
    "clients = filter_df(\n",
    "    [\"client_id\", \"a1\", \"birth_number\"]\n",
    ")\n",
    "# separating birth number into relevant columns\n",
    "# could also do this as string operations\n",
    "# bool mask of all rows with MM+50\n",
    "clients[\"gender\"] = ((clients[\"birth_number\"] // 100) % 100) > 12\n",
    "# remove offset\n",
    "# 100(x + 50) = 100x + 5000\n",
    "clients.loc[clients[\"gender\"], \"birth_number\"] -= 5000\n",
    "# parse date\n",
    "clients[\"birth_number\"] += 19000000  # see above cell\n",
    "clients[\"birth_number\"] = pd.to_datetime(clients[\"birth_number\"], format=\"%Y%m%d\")\n",
    "clients[\"birth_number\"] = clients[\"birth_number\"].dt.strftime(DATE_FORMAT_SQL)\n",
    "cur.executemany(\n",
    "    \"INSERT INTO Client VALUES (?, ?, ?, ?)\",\n",
    "    clients.itertuples()\n",
    ")\n",
    "\n",
    "dispositions = filter_df(\n",
    "    [\"disp_id\", \"account_id\", \"client_id\", \"disp_type\"]\n",
    ")\n",
    "# dispo elysium\n",
    "cur.executemany(\n",
    "    \"INSERT INTO Disposition VALUES (?, ?, ?, ?);\",\n",
    "    dispositions.itertuples()\n",
    ")\n",
    "\n",
    "credit_cars = filter_df(\n",
    "    [\"card_id\", \"disp_id\", \"card_type\", \"card_issued\"]\n",
    ")\n",
    "credit_cars[\"card_issued\"] = credit_cars[\"card_issued\"].dt.strftime(DATE_FORMAT_SQL)\n",
    "cur.executemany(\n",
    "    \"INSERT INTO CreditCard VALUES (?, ?, ?, ?);\",\n",
    "    credit_cars.itertuples()\n",
    ")\n",
    "\n",
    "cities = filter_df(\n",
    "    [f\"a{i}\" for i in range(1, 16+1)]\n",
    ")\n",
    "cur.executemany(\n",
    "    \"INSERT INTO City VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\",\n",
    "    cities.itertuples()\n",
    ")\n",
    "\n",
    "cur.close()\n",
    "con.commit()\n",
    "con.close()\n",
    "print(\"Inserting data complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56000f9f",
   "metadata": {
    "id": "56000f9f",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "----\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd4f6c6",
   "metadata": {
    "id": "bbd4f6c6"
   },
   "source": [
    "## Task 3: Research Design (25 Marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d4db00",
   "metadata": {
    "id": "26d4db00"
   },
   "source": [
    "Using the database designed in Task 2, design and implement **five** potential modelling solutions to achieve the aim of the Data Intelligence team. You need to provide clear justifications about the techniques selected in the context of the 'problem in hand'. Your design must consist of a combination of inferential statistics, supervised learning algorithms, and unsupervised learning algorithms, and include **at least one** of those techniques. Finally, your modelling solutions should be of sufficient complexity, combining information from multiple tables from the database built in Task 2, as appropriate. Your answer should clearly show the queries made to the database. If amendments are made to the database, the commands should be clearly included in your answer.\n",
    "\n",
    "Your answer should clearly cover the following:\n",
    "* Any assumptions you are making about the given scenario;\n",
    "* Any data processing and data integrity steps you would undertake to make the data fit for purpose;\n",
    "* Which technique(s) you would apply for each solution and why;\n",
    "* An evaluation of the techniques applied in terms of the accuracy of their results (or any other suitable evaluation measure);\n",
    "* Algorithmic parameters should be adequately stated and discussed;\n",
    "* A discussion of ethical considerations arising from the solutions selected.\n",
    "\n",
    "**World Limit**: 500 words. This limit applies only to the explanations. There is no limit on any associated code or figures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VVfHwzLCX_NX",
   "metadata": {
    "id": "VVfHwzLCX_NX"
   },
   "source": [
    "**Write your answer here (text cell(s) to be used, as appropriate)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cc2086",
   "metadata": {
    "id": "a9cc2086"
   },
   "outputs": [],
   "source": [
    "### Write your answer here (code cell(s) to be used, as appropriate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a552f4c6",
   "metadata": {
    "id": "a552f4c6"
   },
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f808a0fa",
   "metadata": {
    "id": "f808a0fa"
   },
   "source": [
    "## Task 4: Experimental Results and Analysis (25 Marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71f250b",
   "metadata": {
    "id": "c71f250b"
   },
   "source": [
    "Given the **five** modelling solutions implemented above, analyse, discuss and present your findings to the key stakeholders of the bank.\n",
    "\n",
    "Your answer should clearly cover the following:\n",
    "* Present your findings in a clear and concise manner;\n",
    "* Discuss your results in the context of the selected solution;\n",
    "* Discuss how these results can help the bank in performing customer risk assessment and establishing customer retention strategies;\n",
    "* Present the limitations (if any) of your solutions in a clear and concise manner.\n",
    "\n",
    "**World Limit**: 500 words. This limit applies only to the explanations. There is no limit on any associated code or figures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sXb02r__Ykgr",
   "metadata": {
    "id": "sXb02r__Ykgr"
   },
   "source": [
    "**Write your answer here (text cell(s) to be used, as appropriate)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521811e9",
   "metadata": {
    "id": "521811e9"
   },
   "outputs": [],
   "source": [
    "### Write your answer here (code cell(s) to be used, as appropriate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dc2a18",
   "metadata": {
    "id": "d2dc2a18"
   },
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728dd77f",
   "metadata": {
    "id": "728dd77f"
   },
   "source": [
    "## Task 5: Conclusion (10 Marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be71ded",
   "metadata": {
    "id": "5be71ded"
   },
   "source": [
    "Given the insights derived from Tasks 1-4, provide a conclusion that clearly covers the following:\n",
    "* A summary of the main points;\n",
    "* A discussion of the significance of your results;\n",
    "* Any recommendation(s) resulting from your analysis;\n",
    "* Any overall ethical considerations arising from the data analysis of this business domain.\n",
    "\n",
    "**World Limit**: 300 words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OmyhUuiqZc70",
   "metadata": {
    "id": "OmyhUuiqZc70"
   },
   "source": [
    "**Write your answer here (text cell(s) to be used, as appropriate)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334be1b5",
   "metadata": {
    "id": "334be1b5"
   },
   "outputs": [],
   "source": [
    "### Write your answer here (code cell(s) to be used, as appropriate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bd1577",
   "metadata": {
    "id": "a1bd1577"
   },
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce07aa2",
   "metadata": {
    "id": "dce07aa2"
   },
   "source": [
    "## Overall Academic Quality (10 Marks)\n",
    "10 marks are allocated for the clarity and cohesiveness of your answers (both text and code) across all tasks with appropriate, relevant and effective analysis and presentation of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9440ef2b",
   "metadata": {
    "id": "9440ef2b"
   },
   "source": [
    "## Deliverables\n",
    "\n",
    "You should submit the following to the submission point on the teaching portal:\n",
    "\n",
    "1. the SQLite database produced in Task 2;\n",
    "2. the completed Jupyter notebook (both .ipynb and HTML files) that also includes the SQL statements (Task 2), the research design and its implementation (Task 3), and the analysis and presentation of your results (Task 4);\n",
    "3. any figures or diagrams that are included in your answers in the Jupyter notebook.\n",
    "\n",
    "For each task where text is required, we have provided guidelines above on the suggested word counts. Exceeding the word count will result in any work beyond the word count being disregarded when assessing."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
